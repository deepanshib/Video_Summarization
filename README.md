# Video_Summarization

Understanding the activities of humans from videos is a demanding task in computer vision.
Identifying the actions being accomplished by the human in the video sequence automatically
and tagging their actions is the prime functionality of intelligent video systems. The goal of
activity recognition is to identify the actions and objectives of one or more objects from a series
of examination on the action of object and their environmental condition. The major
applications of Human Activity Recognition vary from Content-based Video Analytics,
Robotics, Human-Computer Interaction, Human fall detection, Ambient Intelligence, Visual
Surveillance, Video Indexing etc.
Activity recognition aims to recognize the actions and goals of one or more agents from a series
of observations on the agentâ€™s actions and the environmental conditions. We aim to develop a
model that will help in activity recognition using the Convolutional Neural Network,
Generative adversarial networks and Long Short-Term memory, an RNN variant that was
designed to store and access information in a long tie sequence

### Technology Used
- Python
- PyTorch
- Google Colab


### Concept

As the video dataset available on internet is not enough to train well and it needs more of computation as well, hence a model is built to combine image processing and video dataset together to build a model that could understand the activities in a video.

##### Note
All files are not added in the repository.

##### Research Paper

https://www.ijitee.org/wp-content/uploads/papers/v8i8/H6775068819.pdf


